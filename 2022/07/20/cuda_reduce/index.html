<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="H.J. Chen">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://hjchen-thu.github.io/2022/07/20/cuda_reduce/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="CUDA implementation for reduce operation">
<meta property="og:type" content="article">
<meta property="og:title" content="[CUDA]reduce">
<meta property="og:url" content="https://hjchen-thu.github.io/2022/07/20/cuda_reduce/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="CUDA implementation for reduce operation">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/hjchen-thu/picb/img_blog/image-20240331211607423.png">
<meta property="article:published_time" content="2022-07-19T16:00:00.000Z">
<meta property="article:modified_time" content="2024-05-05T14:56:12.710Z">
<meta property="article:author" content="H.J. Chen">
<meta property="article:tag" content="CUDA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/hjchen-thu/picb/img_blog/image-20240331211607423.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/personal/avatar.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/personal/avatar.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/personal/avatar.svg">
    <!--- Page Info-->
    
    <title>
        
            [CUDA]reduce -
        
        H.J. Chen&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">


    
        
<link rel="stylesheet" href="/assets/build/styles.css">

    

    
<link rel="stylesheet" href="/fonts/fonts.css">

    
<link rel="stylesheet" href="/fonts/Satoshi/satoshi.css">

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">

    <!--- Font Part-->
    
    
    
        <link href="" rel="stylesheet">
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    window.config = {"hostname":"hjchen-thu.github.io","root":"/","language":"en","path":"search.xml"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":false,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":false,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/picture/s1.jpg","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":true,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"Welcome, traveler :)","subtitle":{"text":["May you find inspiration and joy here (scroll down ↓)"],"hitokoto":{"enable":false,"api":"https://v1.hitokoto.cn"},"typing_speed":40,"backing_speed":10,"starting_delay":500,"backing_delay":1500,"loop":false,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":false,"links":{"github":"https://github.com/hjchen-thu","zhihu":"https://www.zhihu.com/people/baytoro","email":"guaguabear@hotmail.com"},"qrs":null}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":true,"type":"fixed","audios":[{"name":"MapleStory Title","artist":"MapleStory","url":"/music/MapleStory Title.mp3","cover":"/picture/maple.jpeg"},{"name":"Above the Treetops","artist":"MapleStory","url":"/music/Above the Treetops.mp3","cover":"/picture/maple.jpeg"},{"name":"When the Morning Comes","artist":"MapleStory","url":"/music/When the Morning Comes.mp3","cover":"/picture/maple.jpeg"},{"name":"Missing You","artist":"MapleStory","url":"/music/Missing You.mp3","cover":"/picture/maple.jpeg"},{"name":"Shinin' Harbor","artist":"MapleStory","url":"/music/Shinin' Harbor.mp3","cover":"/picture/maple.jpeg"},{"name":"Snowy Village","artist":"MapleStory","url":"/music/Snowy Village.mp3","cover":"/picture/maple.jpeg"}]},"mermaid":{"enable":true,"version":"9.3.0"}},"version":"2.5.0","navbar":{"auto_hide":true,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"About":{"path":"/about","icon":"fa-regular fa-user"},"Archives":{"icon":"fa-regular fa-archive","submenus":{"Posts":"/archives","Categories":"/categories","Tags":"/tags"}},"GitHub":{"icon":"fa-brands fa-github","path":"https://github.com/hjchen-thu"}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"info","menu_title":"Links","announcement":null,"links":null},"article_date_format":"auto","categories":{"enable":true,"limit":2},"tags":{"enable":true,"limit":5}},"footerStart":"2020/8/17 11:45:14"};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="swup-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container" id="swup">

    

    <div class="main-content-container">


        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                H.J. Chen&#39;s Blog
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/about"  >
                                    
                                        
                                            <i class="fa-regular fa-user"></i>
                                        
                                        ABOUT
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        ARCHIVES&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a href="/archives">POSTS
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a href="/categories">CATEGORIES
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a href="/tags">TAGS
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    target="_blank" rel="noopener" href="https://github.com/hjchen-thu"  >
                                    
                                        
                                            <i class="fa-brands fa-github"></i>
                                        
                                        GITHUB
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer w-full absolute top-0 left-0 bg-background-color">
        <ul class="drawer-navbar-list flex flex-col justify-start items-center">
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/about"  >
                             
                                
                                    <i class="fa-regular fa-user"></i>
                                
                                ABOUT
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                ARCHIVES&nbsp;<i class="group-hover:rotate-180 transition-transform fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="drawer-navbar-item text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" href="/archives">POSTS</a>
                            </li>
                        
                            <li class="drawer-navbar-item text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" href="/categories">CATEGORIES</a>
                            </li>
                        
                            <li class="drawer-navbar-item text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" href="/tags">TAGS</a>
                            </li>
                        
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        target="_blank" rel="noopener" href="https://github.com/hjchen-thu"  >
                             
                                
                                    <i class="fa-brands fa-github"></i>
                                
                                GITHUB
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="post-page-container">
    <div class="article-content-container">

        <div class="article-title">
            
                
                
                <img src="https://cdn.jsdelivr.net/gh/hjchen-thu/picb/img_blog/00_m.png" alt="[CUDA]reduce" class="max-w-none"/>
                
                <h1 class="article-title-cover">[CUDA]reduce</h1>
            
            </div>
            
                    
        
        
            <div class="article-header flex flex-row gap-2 items-center">
                <div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
                    <img src="/personal/avatar.svg">
                </div>
                <div class="info flex flex-col justify-between">
                    <div class="author flex items-center">
                        <span class="name text-default-text-color text-lg font-semibold">H.J. Chen</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2022-07-20</span>
        <span class="mobile">2022-07-20</span>
        <span class="hover-info">Created</span>
    </span>
    
        <!-- <span class="article-date article-meta-item"> -->
            <!-- <i class="fa-regular fa-wrench"></i>&nbsp; -->
            <!-- <span class="desktop">2024-05-05 22:56:12</span>
            <span class="mobile">2024-05-05 22:56:12</span> -->
            <!-- <span class="hover-info">Updated</span> -->
        <!-- </span> -->
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/Work-hard/">Work hard</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/Work-hard/Note/">Note</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/Work-hard/Note/Coding/">Coding</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/CUDA/">CUDA</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        


        <div class="article-content markdown-body">
            <h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a class="link" target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html">https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/426978026">https://zhuanlan.zhihu.com/p/426978026 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
<h2 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h2><p>Reduction problems are a common category of questions encountered in interviews. Compared to elementwise problems, where each thread independently performs tasks, reduction problems become more complex due to the involvement of synchronization and communication between threads. Additionally, these problems can leverage the previously introduced optimization techniques for vectorized memory access, which adds a layer of complexity in terms of thought process.<br>The <code>reductions.cu</code> file primarily implements the following three kernel functions for reduction summation:</p>
<ol>
<li>The most basic <code>atomic_reduction()</code>, which extensively utilizes the <code>atomicAdd()</code> function.</li>
<li>The sweep style reduction sum <code>reduction_a()</code>, which calls <code>atomicAdd</code> once at the end.</li>
<li>The warp shuffle reduction <code>reduction_ws()</code>, which also calls <code>atomicAdd</code> once at the end.</li>
</ol>
<p><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/hjchen-thu/picb/img_blog/image-20240331211607423.png" alt="image-20240331211607423"></p>
<p>Theory: The <code>atomic_reduction()</code> is the slowest because it heavily relies on the <code>atomicAdd()</code> function. Compared to <code>reduction_a</code>, <code>reduction_ws</code> tends to perform better due to its minimal use of shared memory.</p>
<p>Observed Phenomena:</p>
<ol>
<li>As the data size increases, the performance advantage of <code>reduce_ws</code> over <code>reduction_a</code> diminishes.</li>
<li>The use of the <code>atomicAdd</code> function affects the Memory utilization rate, and this impact does not vary with the scale of the data.</li>
</ol>
<p>Regarding the first point: Both <code>reduce_ws</code> and <code>reduction_a</code> require loading data within a grid-stride loop initially. As the data size grows, the time taken to load the data becomes the dominant factor in the overall time consumption. At this juncture, the specific method of performing reduction matters less, hence the time difference narrows with increasing data sizes. In theory, warp shuffle should offer better performance than the classic reduction sum, but in practice, it still depends on the specific data scale of the problem at hand and requires a detailed analysis.</p>
<p>Regarding the second point: The impact of the <code>atomicAdd</code> function on performance is significant because it can reduce the Memory utilization rate to a very low level, and this is difficult to improve by simply changing the data scale.</p>
<h2 id="Usefull-basic-reduction-functions"><a href="#Usefull-basic-reduction-functions" class="headerlink" title="Usefull basic reduction functions"></a>Usefull basic reduction functions</h2><p>Here is a collection of some fundamental reduction kernel functions:</p>
<h3 id="warp-reduce-sum"><a href="#warp-reduce-sum" class="headerlink" title="warp reduce sum"></a>warp reduce sum</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//__shfl_down_sync performs a tree-reduction to compute the sum of the val variable held by </span></span><br><span class="line"><span class="comment">//each thread in a warp. At the end of the loop, val of the first thread in the warp </span></span><br><span class="line"><span class="comment">//contains the sum</span></span><br><span class="line"><span class="comment">//https://developer.nvidia.com/blog/using-cuda-warp-level-primitives</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">unsigned</span> <span class="type">int</span> blockSize&gt;</span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">float</span> <span class="title">warp_reduce_sum</span><span class="params">(<span class="type">float</span> val)</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>)val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, <span class="number">16</span>); <span class="comment">// 0-16, 1-17, 2-18, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>)val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, <span class="number">8</span>);<span class="comment">// 0-8, 1-9, 2-10, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>)val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, <span class="number">4</span>);<span class="comment">// 0-4, 1-5, 2-6, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>)val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, <span class="number">2</span>);<span class="comment">// 0-2, 1-3, 4-6, 5-7, etc.</span></span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>)val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, <span class="number">1</span>);<span class="comment">// 0-1, 2-3, 4-5, etc.</span></span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">}</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15</span></span><br><span class="line"><span class="comment">16 17 18 19 20 21 22 23 24 25 26  27  28  29  30  31</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></div>

<h3 id="warp-reduce-max"><a href="#warp-reduce-max" class="headerlink" title="warp reduce max"></a>warp reduce max</h3><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">template &lt;unsigned int blockSize&gt;</span><br><span class="line">__device__ __forceinline__ float warp_reduce_max(float val) {</span><br><span class="line">    if (blockSize &gt;= 32)val = fmaxf(val, __shfl_down_sync(0xffffffff, val, 16)); // 0-16, 1-17, 2-18, etc.</span><br><span class="line">    if (blockSize &gt;= 16)val = fmaxf(val, __shfl_down_sync(0xffffffff, val, 8));// 0-8, 1-9, 2-10, etc.</span><br><span class="line">    if (blockSize &gt;= 8)val = fmaxf(val, __shfl_down_sync(0xffffffff, val, 4));// 0-4, 1-5, 2-6, etc.</span><br><span class="line">    if (blockSize &gt;= 4)val = fmaxf(val, __shfl_down_sync(0xffffffff, val, 2));// 0-2, 1-3, 4-6, 5-7, etc.</span><br><span class="line">    if (blockSize &gt;= 2)val = fmaxf(val, __shfl_down_sync(0xffffffff, val, 1));// 0-1, 2-3, 4-5, etc.</span><br><span class="line">    return val;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="block-reduce-sum"><a href="#block-reduce-sum" class="headerlink" title="block reduce sum"></a>block reduce sum</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在一个block里面求和，先每个warp内部求和，结果保存在每个warp第一个线程的寄存器val里</span></span><br><span class="line"><span class="comment">//然后将val暂存在共享内存sdata里</span></span><br><span class="line"><span class="comment">//最后在第一个warp里，把val从共享内存里再读取出来，对warp之间再求和</span></span><br><span class="line"><span class="function">__device__  <span class="type">float</span> <span class="title">block_reduce_sum</span><span class="params">(<span class="type">float</span> val)</span> </span>{</span><br><span class="line">    <span class="comment">// 一个block里最多32个warps，因为最多1024个线程</span></span><br><span class="line">    __shared__ <span class="type">float</span> sdata[<span class="number">32</span>];</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> warpID = threadIdx.x / warpSize;</span><br><span class="line">    <span class="type">int</span> lane = threadIdx.x % warpSize;<span class="comment">//0~31</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//每个warp内部求和</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)  </span><br><span class="line">          val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, offset);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lane == <span class="number">0</span>) sdata[warpID] = val;<span class="comment">//每个warp里第一个线程的寄存器保存这个warp内部求和的结果</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(warpID == <span class="number">0</span>){</span><br><span class="line">        val = (lane &lt; blockDim.x / warpSize) ? sdata[lane] : <span class="number">0.0f</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)  </span><br><span class="line">            val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, offset);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="block-reduce-max"><a href="#block-reduce-max" class="headerlink" title="block reduce max"></a>block reduce max</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__device__ <span class="type">float</span> <span class="title">block_reduce_max</span><span class="params">(<span class="type">float</span> val)</span> </span>{</span><br><span class="line">    __shared__ <span class="type">float</span> sdata[<span class="number">32</span>];</span><br><span class="line">    <span class="type">int</span> warpID = threadIdx.x / warpSize;</span><br><span class="line">    <span class="type">int</span> lane = threadIdx.x % warpSize;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)  </span><br><span class="line">        val = <span class="built_in">fmaxf</span>(val, __shfl_xor_sync(<span class="number">0xffffffff</span>, val, offset));</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> (lane == <span class="number">0</span>) sdata[warpID] = val;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(warpID == <span class="number">0</span>){</span><br><span class="line">        val = (lane &lt; blockDim.x / warpSize) ? sdata[lane] : -FLT_MAX;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)  </span><br><span class="line">            val = <span class="built_in">fmaxf</span>(val, __shfl_xor_sync(<span class="number">0xffffffff</span>, val, offset));<span class="comment">//求最大值的时候必须得是__shfl_xor_sync</span></span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="All-reduce-sum"><a href="#All-reduce-sum" class="headerlink" title="All reduce sum"></a>All reduce sum</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Block All Reduce Sum</span></span><br><span class="line"><span class="comment">// grid(N/256), block(256)</span></span><br><span class="line"><span class="comment">// input: Nx1, output=sum(input)</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_ws</span><span class="params">(<span class="type">float</span> *gdata, <span class="type">float</span> *out)</span></span>{</span><br><span class="line">     __shared__ <span class="type">float</span> sdata[<span class="number">32</span>];<span class="comment">//最多就32个warp，因为线程数最多是1024</span></span><br><span class="line">     <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">     <span class="type">int</span> idx = threadIdx.x+blockDim.x*blockIdx.x;<span class="comment">//&lt;&lt;&lt;640,256&gt;&gt;&gt;</span></span><br><span class="line"></span><br><span class="line">     <span class="type">float</span> val = <span class="number">0.0f</span>;<span class="comment">//这是每个线程独有的本地变量</span></span><br><span class="line">     <span class="type">unsigned</span> mask = <span class="number">0xFFFFFFFF</span>U;</span><br><span class="line"></span><br><span class="line">     <span class="type">int</span> lane = threadIdx.x % warpSize;<span class="comment">//0~31</span></span><br><span class="line">     <span class="type">int</span> warpID = threadIdx.x / warpSize;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">while</span> (idx &lt; N) {  <span class="comment">// grid stride loop to load </span></span><br><span class="line">        val += gdata[idx];</span><br><span class="line">        idx += gridDim.x*blockDim.x;  </span><br><span class="line">      }</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 1st warp-shuffle reduction</span></span><br><span class="line">   <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) </span><br><span class="line">       val += __shfl_xor_sync(mask, val, offset);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lane == <span class="number">0</span>) sdata[warpID] = val; <span class="comment">//warp内部求和, 每个线程都把warp内部求和的结果放在自己本地的val变量上，但是只有lane==0的val被保存进shared_memory[warpID]里</span></span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (warpID == <span class="number">0</span>)</span><br><span class="line">    {</span><br><span class="line"> <span class="comment">// reload val from shared mem if warp existed</span></span><br><span class="line">       val = (tid &lt; blockDim.x/warpSize)?sdata[lane]:<span class="number">0</span>;<span class="comment">//为什么用lane而不是warpID去索引？ 因为warpID是0才会进来</span></span><br><span class="line">       <span class="comment">//tid 小于8，那么lane也是0~7之间，可以用来索引sdata</span></span><br><span class="line"> <span class="comment">// final warp-shuffle reduction</span></span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)  </span><br><span class="line">          val += __shfl_down_sync(mask, val, offset);</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span>(tid == <span class="number">0</span>) <span class="built_in">atomicAdd</span>(out, val);<span class="comment">//将所有block内部求和的结果再一次汇总</span></span><br><span class="line">     }</span><br><span class="line">  }</span><br></pre></td></tr></table></figure></div>



<h3 id="All-reduce-sum-float4"><a href="#All-reduce-sum-float4" class="headerlink" title="All reduce sum float4"></a>All reduce sum float4</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Block All Reduce Sum + float4</span></span><br><span class="line"><span class="comment">// grid(N/256/4), block(256)</span></span><br><span class="line"><span class="comment">// input: Nx1, output=sum(input)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> warpSize 32</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="type">const</span> <span class="type">int</span> block_size </span>= <span class="number">256</span>/<span class="number">4</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_ws_float4</span><span class="params">(<span class="type">float</span> *gdata, <span class="type">float</span> *out)</span></span>{</span><br><span class="line"></span><br><span class="line">   __shared__ <span class="type">float</span> sdata[<span class="number">32</span>];<span class="comment">//最多就32个warp，因为线程数最多是1024</span></span><br><span class="line">   <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">   <span class="type">int</span> idx = (blockIdx.x * blockDim.x + threadIdx.x) * <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">   <span class="type">float</span> val = <span class="number">0.0f</span>;<span class="comment">//这是每个线程独有的本地变量,不用担心读写同步的问题</span></span><br><span class="line">   <span class="type">unsigned</span> mask = <span class="number">0xFFFFFFFF</span>U;</span><br><span class="line">   <span class="type">int</span> lane = threadIdx.x % warpSize;<span class="comment">//0~31</span></span><br><span class="line">   <span class="type">int</span> warpID = threadIdx.x / warpSize;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">while</span> (idx &lt; N) {  <span class="comment">// grid stride loop to load </span></span><br><span class="line">      float4 tmp_input = <span class="built_in">FLOAT4</span>(gdata[idx]); </span><br><span class="line">      val += tmp_input.x;</span><br><span class="line">      val += tmp_input.y;</span><br><span class="line">      val += tmp_input.z;</span><br><span class="line">      val += tmp_input.w;</span><br><span class="line">      idx += (gridDim.x*blockDim.x) * <span class="number">4</span>;  </span><br><span class="line">   }</span><br><span class="line">   <span class="comment">// 1st warp-shuffle reduction</span></span><br><span class="line">   <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)</span><br><span class="line">      val += __shfl_xor_sync(mask, val, offset);</span><br><span class="line">       </span><br><span class="line">   <span class="keyword">if</span> (lane == <span class="number">0</span>) sdata[warpID] = val; <span class="comment">//warp内部求和, 每个线程都把warp内部求和的结果放在自己本地的val变量上，但是只有lane==0的val被保存进shared_memory[warpID]里</span></span><br><span class="line">   __syncthreads();</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span>(warpID == <span class="number">0</span>){</span><br><span class="line">      val = (tid &lt; blockDim.x/warpSize) ? sdata[lane] : <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)  </span><br><span class="line">          val += __shfl_xor_sync(mask, val, offset);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span>(tid == <span class="number">0</span>) <span class="built_in">atomicAdd</span>(out, val);</span><br><span class="line">   }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h2 id="Complex-scenario"><a href="#Complex-scenario" class="headerlink" title="Complex scenario"></a>Complex scenario</h2><h3 id="dot-product"><a href="#dot-product" class="headerlink" title="dot product"></a>dot product</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Dot Product</span></span><br><span class="line"><span class="comment">// grid(N/256), block(256)</span></span><br><span class="line"><span class="comment">// a: Nx1, b: Nx1, out=sum(elementwise_mul(a,b))</span></span><br><span class="line"><span class="comment">// dot_product&lt;&lt;&lt;CeilDiv(N, block_size), block_size&gt;&gt;&gt;(d_A, d_B, d_C, N);</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">dot_product</span><span class="params">(<span class="type">float</span>* a, <span class="type">float</span>* b, <span class="type">float</span>* c, <span class="type">int</span> N)</span></span>{</span><br><span class="line">    </span><br><span class="line">    __shared__ <span class="type">float</span> sdata[<span class="number">32</span>];</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">int</span> idx = blockIdx.x * blockDim.x + tid;</span><br><span class="line">  </span><br><span class="line">    <span class="type">float</span> val = <span class="number">0.0f</span>;</span><br><span class="line">  </span><br><span class="line">    <span class="type">int</span> warpID = threadIdx.x / warpSize;</span><br><span class="line">    <span class="type">int</span> lane   = threadIdx.x % warpSize; </span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(idx &lt; N)</span><br><span class="line">    {</span><br><span class="line">        val += a[idx] * b[idx]; </span><br><span class="line">        idx += gridDim.x * blockDim.x;</span><br><span class="line">    }</span><br><span class="line">    __syncthreads();</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) {</span><br><span class="line">        val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, offset);<span class="comment">//__shfl_xor_sync(0xffffffff, val,offset);</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lane == <span class="number">0</span>) sdata[warpID] = val;</span><br><span class="line">    __syncthreads();</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span>(warpID == <span class="number">0</span>)</span><br><span class="line">    {</span><br><span class="line">      val = (tid &lt; blockDim.x / warpSize) ? sdata[lane] : <span class="number">0.0f</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)</span><br><span class="line">        val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, offset);<span class="comment">//__shfl_xor_sync(0xffffffff, val,offset);</span></span><br><span class="line">      <span class="keyword">if</span>(tid == <span class="number">0</span>) <span class="built_in">atomicAdd</span>(c, val);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="dot-product-float4"><a href="#dot-product-float4" class="headerlink" title="dot product float4"></a>dot product float4</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Dot Product</span></span><br><span class="line"><span class="comment">// grid(N/256), block(256)</span></span><br><span class="line"><span class="comment">// a: Nx1, b: Nx1, out=sum(elementwise_mul(a,b))</span></span><br><span class="line"><span class="comment">// dot_product&lt;&lt;&lt;CeilDiv(N, block_size), block_size&gt;&gt;&gt;(d_A, d_B, d_C, N);</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">dot_product</span><span class="params">(<span class="type">float</span>* a, <span class="type">float</span>* b, <span class="type">float</span>* c, <span class="type">int</span> N)</span></span>{</span><br><span class="line">    </span><br><span class="line">    __shared__ <span class="type">float</span> sdata[<span class="number">32</span>];</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">int</span> idx = blockIdx.x * blockDim.x + tid;</span><br><span class="line">  </span><br><span class="line">    <span class="type">float</span> val = <span class="number">0.0f</span>;</span><br><span class="line">  </span><br><span class="line">    <span class="type">int</span> warpID = threadIdx.x / warpSize;</span><br><span class="line">    <span class="type">int</span> lane   = threadIdx.x % warpSize; </span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(idx &lt; N)</span><br><span class="line">    {</span><br><span class="line">        val += a[idx] * b[idx]; </span><br><span class="line">        idx += gridDim.x * blockDim.x;</span><br><span class="line">    }</span><br><span class="line">    __syncthreads();</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) {</span><br><span class="line">        val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, offset);<span class="comment">//__shfl_xor_sync(0xffffffff, val,offset);</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lane == <span class="number">0</span>) sdata[warpID] = val;</span><br><span class="line">    __syncthreads();</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span>(warpID == <span class="number">0</span>)</span><br><span class="line">    {</span><br><span class="line">      val = (tid &lt; blockDim.x / warpSize) ? sdata[lane] : <span class="number">0.0f</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> offset = warpSize/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>)</span><br><span class="line">        val += __shfl_down_sync(<span class="number">0xffffffff</span>, val, offset);<span class="comment">//__shfl_xor_sync(0xffffffff, val,offset);</span></span><br><span class="line">      <span class="keyword">if</span>(tid == <span class="number">0</span>) <span class="built_in">atomicAdd</span>(c, val);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<h3 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//softmax_v2&lt;&lt;&lt;CeilDiv((int)N, block_size), block_size&gt;&gt;&gt;(d_A, d_B, d_sum);</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">softmax_v2</span><span class="params">(<span class="type">float</span>* x, <span class="type">float</span>* y, <span class="type">float</span>* total)</span> </span>{</span><br><span class="line">  </span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> idx = blockIdx.x * blockDim.x + tid;</span><br><span class="line">    <span class="type">float</span> sum = (idx &lt; N) ? <span class="built_in">expf</span>(x[idx]) : <span class="number">0.0f</span>;</span><br><span class="line"></span><br><span class="line">    sum = <span class="built_in">block_reduce_sum</span>(sum);</span><br><span class="line">    <span class="type">int</span> warpID = tid / warpSize;</span><br><span class="line">    <span class="keyword">if</span>(warpID == <span class="number">0</span>){</span><br><span class="line">        <span class="keyword">if</span> (tid == <span class="number">0</span>) <span class="built_in">atomicAdd</span>(total, sum);</span><br><span class="line">        __threadfence();  </span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (idx &lt; N) y[idx] = <span class="built_in">expf</span>(x[idx]) / (*total);</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="safe-softmax"><a href="#safe-softmax" class="headerlink" title="safe softmax"></a>safe softmax</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Safe Softmax x: Nx1, y: Nx1</span></span><br><span class="line"><span class="comment">// softmax_safe&lt;&lt;&lt;CeilDiv((int)N, block_size), block_size&gt;&gt;&gt;(d_A, d_B, d_sum)</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">softmax_safe</span><span class="params">(<span class="type">float</span>* x, <span class="type">float</span>* y, <span class="type">float</span>* total)</span> </span>{</span><br><span class="line">  </span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> idx = blockIdx.x * blockDim.x + tid; </span><br><span class="line">  </span><br><span class="line">    <span class="type">float</span> ori_val = (idx &lt; N) ? x[idx] : (-FLT_MAX);<span class="comment">//FLT_MIN是正数</span></span><br><span class="line">    <span class="type">float</span> max_val = <span class="built_in">block_reduce_max</span>(ori_val);</span><br><span class="line">    <span class="type">float</span> exp_val = (idx &lt; N) ? <span class="built_in">expf</span>(ori_val - max_val) : <span class="number">0.0f</span>;</span><br><span class="line">    <span class="type">float</span> sum = <span class="built_in">block_reduce_sum</span>(exp_val);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> warpID = tid / warpSize;</span><br><span class="line">    <span class="keyword">if</span>(warpID == <span class="number">0</span>)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (tid == <span class="number">0</span>) <span class="built_in">atomicAdd</span>(total, sum);</span><br><span class="line">        __threadfence(); </span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (idx &lt; N) y[idx] = exp_val / (*total);</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="layernorm"><a href="#layernorm" class="headerlink" title="layernorm"></a>layernorm</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Layer Norm: x: NxK(K=256&lt;1024), y': NxK, y'=x-mean(x)/std(x) each row</span></span><br><span class="line"><span class="comment">// mean(x) = sum(x)/K, 1/std(x) = rsqrtf( sum( (x-mean(x))^2 )/K ) each row</span></span><br><span class="line"><span class="comment">// grid(N), block(K&lt;1024) N=batch_size*seq_len, K=hidden_size</span></span><br><span class="line"><span class="comment">// y=y'*g + b (g: scale, b: bias)</span></span><br><span class="line"><span class="comment">//layer_norm&lt;&lt;&lt;CeilDiv((int)N, block_size),block_size&gt;&gt;&gt;(d_A, d_B, g, b, row, block_size)</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">layer_norm</span><span class="params">(<span class="type">float</span>* x, <span class="type">float</span>* y, <span class="type">float</span> g, <span class="type">float</span> b, <span class="type">int</span> row, <span class="type">int</span> col)</span> </span>{</span><br><span class="line">  </span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x; <span class="comment">// 0..col-1</span></span><br><span class="line">    <span class="type">int</span> bid = blockIdx.x; <span class="comment">// 0..row-1</span></span><br><span class="line">    <span class="type">int</span> idx = bid * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> epsilon = <span class="number">1e-5</span>f;</span><br><span class="line"></span><br><span class="line">    __shared__ <span class="type">float</span> s_mean; <span class="comment">// 一个block计算一行的均值，s_mean被这个block里所有线程共享</span></span><br><span class="line">    __shared__ <span class="type">float</span> s_variance; <span class="comment">// 一个block计算一行的方差，s_variance被这个block里所有线程共享</span></span><br><span class="line">    <span class="type">float</span> value = (idx &lt; row * col) ? x[idx] : <span class="number">0.0f</span>; <span class="comment">// 只加载一次</span></span><br><span class="line">    <span class="type">float</span> sum = <span class="built_in">block_reduce_sum</span>(value);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) s_mean = sum / (<span class="type">float</span>) col;</span><br><span class="line">    <span class="comment">//一个block里所有线程同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="type">float</span> variance = (value - s_mean) * (value - s_mean);</span><br><span class="line">    variance = <span class="built_in">block_reduce_sum</span>(variance);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) s_variance = <span class="built_in">rsqrtf</span>(variance / (<span class="type">float</span>) col + epsilon);</span><br><span class="line">    <span class="comment">//一个block里所有线程同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="keyword">if</span> (idx &lt; row * col) y[idx] = ((value - s_mean) * s_variance) * g + b;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="layernorm-float4"><a href="#layernorm-float4" class="headerlink" title="layernorm float4"></a>layernorm float4</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Layer Norm Vec4: x: NxK(K=256&lt;1024), y': NxK, y'=x-mean(x)/std(x) each row</span></span><br><span class="line"><span class="comment">// mean(x) = sum(x)/K, 1/std(x) = rsqrtf( sum( (x-mean(x))^2 )/K ) each row</span></span><br><span class="line"><span class="comment">// grid(N*K/K), block(K/4&lt;1024) N=batch_size*seq_len, K=hidden_size</span></span><br><span class="line"><span class="comment">// y=y'*g + b (g: scale, b: bias)</span></span><br><span class="line"><span class="comment">//layer_norm_float4_block&lt;&lt;&lt;CeilDiv((int)N, block_size),block_size/4&gt;&gt;&gt;(d_A, d_B, g, b, row, block_size)</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">layer_norm_float4_block</span><span class="params">(<span class="type">float</span>* x, <span class="type">float</span>* y, <span class="type">float</span> g, <span class="type">float</span> b, <span class="type">int</span> N, <span class="type">int</span> K)</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x; <span class="comment">// 0..K-1</span></span><br><span class="line">    <span class="type">int</span> bid = blockIdx.x; <span class="comment">// 0..N-1</span></span><br><span class="line">    <span class="type">int</span> idx = (bid * blockDim.x + threadIdx.x) * <span class="number">4</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> epsilon = <span class="number">1e-5</span>f;</span><br><span class="line"></span><br><span class="line">    __shared__ <span class="type">float</span> s_mean; <span class="comment">// shared within block</span></span><br><span class="line">    __shared__ <span class="type">float</span> s_variance; <span class="comment">// shared within block</span></span><br><span class="line"></span><br><span class="line">    float4 tmp_x = <span class="built_in">FLOAT4</span>(x[idx]);</span><br><span class="line">    <span class="type">float</span> value = (idx &lt; N * K) ? (tmp_x.x + tmp_x.y </span><br><span class="line">                                + tmp_x.z + tmp_x.w) : <span class="number">0.0f</span>;</span><br><span class="line">    <span class="type">float</span> sum = <span class="built_in">block_reduce_sum</span>(value);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) s_mean = sum / (<span class="type">float</span>) K;</span><br><span class="line">    <span class="comment">// wait for s_mean in shared memory to be ready for all threads</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    float4 tmp_x_hat;</span><br><span class="line">    tmp_x_hat.x = tmp_x.x - s_mean;</span><br><span class="line">    tmp_x_hat.y = tmp_x.y - s_mean;</span><br><span class="line">    tmp_x_hat.z = tmp_x.z - s_mean;</span><br><span class="line">    tmp_x_hat.w = tmp_x.w - s_mean;</span><br><span class="line">    <span class="type">float</span> variance = tmp_x_hat.x * tmp_x_hat.x </span><br><span class="line">                    + tmp_x_hat.y * tmp_x_hat.y </span><br><span class="line">                    + tmp_x_hat.z * tmp_x_hat.z </span><br><span class="line">                    + tmp_x_hat.w * tmp_x_hat.w;</span><br><span class="line">    variance = <span class="built_in">block_reduce_sum</span>(variance);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) s_variance = <span class="built_in">rsqrtf</span>(variance / (<span class="type">float</span>) K + epsilon);</span><br><span class="line">    <span class="comment">// wait for s_variance in shared memory to be ready for all threads</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    float4 tmp_y;</span><br><span class="line">    tmp_y.x = tmp_x_hat.x * s_variance * g + b;</span><br><span class="line">    tmp_y.y = tmp_x_hat.y * s_variance * g + b;</span><br><span class="line">    tmp_y.z = tmp_x_hat.z * s_variance * g + b;</span><br><span class="line">    tmp_y.w = tmp_x_hat.w * s_variance * g + b;</span><br><span class="line">    <span class="keyword">if</span> (idx &lt; N * K) <span class="built_in">FLOAT4</span>(y[idx]) = tmp_y;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="rmsnorm"><a href="#rmsnorm" class="headerlink" title="rmsnorm"></a>rmsnorm</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// RMS Norm: x: NxK(K=256&lt;1024), y': NxK, y'=x/rms(x) each row</span></span><br><span class="line"><span class="comment">// 1/rms(x) = rsqrtf( sum(x^2)/K ) each row</span></span><br><span class="line"><span class="comment">// grid(N), block(K&lt;1024) N=batch_size*seq_len, K=hidden_size</span></span><br><span class="line"><span class="comment">// y=y'*g (g: scale)</span></span><br><span class="line"><span class="comment">//rms_norm&lt;&lt;&lt;CeilDiv((int)N, block_size),block_size&gt;&gt;&gt;(d_A, d_B, g, b, row, block_size)</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">rms_norm</span><span class="params">(<span class="type">float</span>* x, <span class="type">float</span>* y, <span class="type">float</span> g, <span class="type">float</span> b, <span class="type">int</span> N, <span class="type">int</span> K)</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x; <span class="comment">// 0..K-1</span></span><br><span class="line">    <span class="type">int</span> bid = blockIdx.x; <span class="comment">// 0..N-1</span></span><br><span class="line">    <span class="type">int</span> idx = bid * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> epsilon = <span class="number">1e-5</span>f;</span><br><span class="line"></span><br><span class="line">    __shared__ <span class="type">float</span> s_variance; <span class="comment">// 一个block里共享的变量</span></span><br><span class="line">    <span class="type">float</span> value = (idx &lt; N * K) ? x[idx] : <span class="number">0.0f</span>; <span class="comment">// 只加载一次</span></span><br><span class="line">    <span class="type">float</span> variance = value * value;</span><br><span class="line">    variance = <span class="built_in">block_reduce_sum</span>(variance);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) s_variance = <span class="built_in">rsqrtf</span>(variance / (<span class="type">float</span>) K + epsilon);</span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="keyword">if</span>(idx == <span class="number">0</span>){</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"idx :%d, value :%f, s_variance :%f\n"</span>, idx, value, s_variance);</span><br><span class="line">    }  </span><br><span class="line">    <span class="keyword">if</span> (idx &lt; N * K) y[idx] = (value * s_variance) * g + b;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>



<h3 id="rmsnorm-float4"><a href="#rmsnorm-float4" class="headerlink" title="rmsnorm float4"></a>rmsnorm float4</h3><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// RMS Norm Vec4: x: NxK(K=256&lt;1024), y': NxK, y'=x/rms(x) each row</span></span><br><span class="line"><span class="comment">// 1/rms(x) = rsqrtf( sum(x^2)/K ) each row</span></span><br><span class="line"><span class="comment">// grid(N), block(K/4&lt;1024) N=batch_size*seq_len, K=hidden_size</span></span><br><span class="line"><span class="comment">// y=y'*g (g: scale)</span></span><br><span class="line"><span class="comment">//rms_norm_float4_block&lt;&lt;&lt;CeilDiv((int)N, block_size),block_size/4&gt;&gt;&gt;(d_A, d_B, g, b, row, block_size)</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">rms_norm_float4_block</span><span class="params">(<span class="type">float</span>* x, <span class="type">float</span>* y, <span class="type">float</span> g, <span class="type">float</span> b, <span class="type">int</span> N, <span class="type">int</span> K)</span> </span>{</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x; <span class="comment">// 0..K-1</span></span><br><span class="line">    <span class="type">int</span> bid = blockIdx.x; <span class="comment">// 0..N-1</span></span><br><span class="line">    <span class="type">int</span> idx = (bid * blockDim.x + threadIdx.x) * <span class="number">4</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> epsilon = <span class="number">1e-5</span>f;</span><br><span class="line"></span><br><span class="line">    __shared__ <span class="type">float</span> s_variance; <span class="comment">//一个block里共享的变量</span></span><br><span class="line">    float4 tmp_x = <span class="built_in">FLOAT4</span>(x[idx]);</span><br><span class="line">    <span class="type">float</span> variance = (idx &lt; N * K) ? (tmp_x.x * tmp_x.x </span><br><span class="line">                                    + tmp_x.y * tmp_x.y </span><br><span class="line">                                    + tmp_x.z * tmp_x.z </span><br><span class="line">                                    + tmp_x.w * tmp_x.w) : <span class="number">0.0f</span>;</span><br><span class="line">    variance = <span class="built_in">block_reduce_sum</span>(variance);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) s_variance = <span class="built_in">rsqrtf</span>(variance / (<span class="type">float</span>) K + epsilon);</span><br><span class="line">    </span><br><span class="line">    __syncthreads(); </span><br><span class="line">    float4 tmp_y;</span><br><span class="line">    tmp_y.x = tmp_x.x * s_variance * g;</span><br><span class="line">    tmp_y.y = tmp_x.y * s_variance * g;</span><br><span class="line">    tmp_y.z = tmp_x.z * s_variance * g;</span><br><span class="line">    tmp_y.w = tmp_x.w * s_variance * g;</span><br><span class="line">    <span class="keyword">if</span> (idx &lt; N * K) <span class="built_in">FLOAT4</span>(y[idx]) = tmp_y;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>


        </div>

        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/CUDA/">#CUDA</a>&nbsp;
                    </li>
                
            </ul>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                        rel="prev"
                        href="/2022/07/25/cuda_sgemv/"
                        >
                            <span class="left arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-left"></i>
                            </span>
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">[CUDA]sgemv</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                        rel="next"
                        href="/2022/07/06/cuda_elementwise/"
                        >
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">[CUDA]element-wise</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        


        
    </div>

    
        <div class="toc-content-container">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">[CUDA]reduce</div>
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-text">Reference</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-Concepts"><span class="nav-text">Basic Concepts</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Usefull-basic-reduction-functions"><span class="nav-text">Usefull basic reduction functions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#warp-reduce-sum"><span class="nav-text">warp reduce sum</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#warp-reduce-max"><span class="nav-text">warp reduce max</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#block-reduce-sum"><span class="nav-text">block reduce sum</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#block-reduce-max"><span class="nav-text">block reduce max</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#All-reduce-sum"><span class="nav-text">All reduce sum</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#All-reduce-sum-float4"><span class="nav-text">All reduce sum float4</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Complex-scenario"><span class="nav-text">Complex scenario</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#dot-product"><span class="nav-text">dot product</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dot-product-float4"><span class="nav-text">dot product float4</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#softmax"><span class="nav-text">softmax</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#safe-softmax"><span class="nav-text">safe softmax</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#layernorm"><span class="nav-text">layernorm</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#layernorm-float4"><span class="nav-text">layernorm float4</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rmsnorm"><span class="nav-text">rmsnorm</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rmsnorm-float4"><span class="nav-text">rmsnorm float4</span></a></li></ol></li></ol>

    </div>
</div>
        </div>
    
</div>



                

            </div>

            

        </div>

        <div class="main-content-footer">
            <footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2020</span>
              -
            
            2024&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">H.J. Chen</a>
        </div>
        
            <script data-swup-reload-script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.5.0</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fa-solid fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fa-solid fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>


    
<script src="/js/libs/Swup.min.js"></script>

<script src="/js/libs/SwupSlideTheme.min.js"></script>

<script src="/js/libs/SwupScriptsPlugin.min.js"></script>

<script src="/js/libs/SwupProgressPlugin.min.js"></script>

<script src="/js/libs/SwupScrollPlugin.min.js"></script>

<script src="/js/libs/SwupPreloadPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>







<script src="/js/tools/imageViewer.js" type="module"></script>

<script src="/js/utils.js" type="module"></script>

<script src="/js/main.js" type="module"></script>

<script src="/js/layouts/navbarShrink.js" type="module"></script>

<script src="/js/tools/scrollTopBottom.js" type="module"></script>

<script src="/js/tools/lightDarkSwitch.js" type="module"></script>

<script src="/js/layouts/categoryList.js" type="module"></script>



    
<script src="/js/tools/localSearch.js" type="module"></script>




    
<script src="/js/tools/codeBlock.js" type="module"></script>




    
<script src="/js/layouts/lazyload.js" type="module"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js" type="module"></script>




    
<script src="/js/libs/mermaid.min.js"></script>

    
<script src="/js/plugins/mermaid.js"></script>





<div class="post-scripts" data-swup-reload-script>
    
        
<script src="/js/libs/anime.min.js"></script>

        
<script src="/js/tools/tocToggle.js" type="module"></script>

<script src="/js/layouts/toc.js" type="module"></script>

<script src="/js/plugins/tabs.js" type="module"></script>

    
</div>


    <div id="aplayer"></div>

<script src="/js/libs/APlayer.min.js"></script>


<script src="/js/plugins/aplayer.js"></script>


</body>
</html>
